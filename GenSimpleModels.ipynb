{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate simple models with complex model's labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Lambda, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, adam\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler, CSVLogger\n",
    "from keras.models import Model, load_model\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import cifar10, normalize and create soft targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset():   \n",
    "    (x_train, y_train_hard), (x_test, y_test_hard) = cifar10.load_data()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    #Z score\n",
    "    mean = np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "    std = np.std(x_train, axis=(0, 1, 2, 3))\n",
    "    x_train = (x_train - mean) / (std + 1e-7) \n",
    "    x_test = (x_test - mean) / (std + 1e-7)\n",
    "\n",
    "    num_classes = 10\n",
    "    y_train_hard = np_utils.to_categorical(y_train_hard, num_classes) #One hot encoding\n",
    "    y_test_hard = np_utils.to_categorical(y_test_hard, num_classes)\n",
    "\n",
    "    model = load_model('TestModel.h5') #Loads trained complex net\n",
    "    ModelCut = Model(inputs=model.input,outputs=model.layers[-2].output) #Gets the same network without last layer\n",
    "    W = model.layers[-1].get_weights()  #Gets last layer weights\n",
    "\n",
    "    y_test_logits = np.dot(ModelCut.predict(x_test), W[0]) + W[1]\n",
    "    y_train_logits = np.dot(ModelCut.predict(x_train), W[0]) + W[1]\n",
    "\n",
    "    return (x_train, y_train_hard, y_train_logits),(x_test, y_test_hard, y_test_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def getSimpleModel(T):         \n",
    "    num_classes = 10\n",
    "\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3),\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Lambda(lambda x: x / T))\n",
    "    model.add(Activation('softmax'))    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train_hard, y_train_logits), (x_test, y_test_hard, y_test_logits) = getDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over different tempeartures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [1, 2, 3, 4, 5]\n",
    "\n",
    "for i, T in enumerate(temperatures):\n",
    "    \n",
    "    model = getSimpleModel(T)\n",
    "    \n",
    "    lrate = 0.01\n",
    "    epochs = 25\n",
    "    batch_size = 64\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    csv_logger = CSVLogger('training.log', separator=',', append=False)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])  \n",
    "\n",
    "    # Apply temperature to the soft results\n",
    "    y_train_soft = softmax(y_train_logits / T, axis = 1)  \n",
    "    \n",
    "    # Train model. Change y_train_soft to y_train_hard to train \"hard\" model\n",
    "    model.fit(x_train, y_train_soft, callbacks=[csv_logger], validation_data=(x_test, y_test_hard), batch_size=batch_size, epochs=epochs)\n",
    "    \n",
    "    # Save model\n",
    "    model.save('SmallModel_t' + str(T) + '.h5')\n",
    "    \n",
    "    # Store train history in csv\n",
    "    log_data = pd.read_csv('training.log', sep=',', engine='python')\n",
    "                            \n",
    "    # Save train history\n",
    "    pickle.dump(log_data, open('t' + str(T) + '_trainLog.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
